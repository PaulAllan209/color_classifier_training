{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red</th>\n",
       "      <th>green</th>\n",
       "      <th>blue</th>\n",
       "      <th>label_Black</th>\n",
       "      <th>label_Blue</th>\n",
       "      <th>label_Brown</th>\n",
       "      <th>label_Green</th>\n",
       "      <th>label_Grey</th>\n",
       "      <th>label_Orange</th>\n",
       "      <th>label_Pink</th>\n",
       "      <th>label_Purple</th>\n",
       "      <th>label_Red</th>\n",
       "      <th>label_White</th>\n",
       "      <th>label_Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>139</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>83</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144</td>\n",
       "      <td>249</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168</td>\n",
       "      <td>25</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>182</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5051</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5052 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      red  green  blue  label_Black  label_Blue  label_Brown  label_Green  \\\n",
       "0      20    139   240            0           1            0            0   \n",
       "1     174     83    72            0           0            1            0   \n",
       "2     144    249   131            0           0            0            1   \n",
       "3     168     25   156            0           0            0            0   \n",
       "4      30    182   136            0           0            0            1   \n",
       "...   ...    ...   ...          ...         ...          ...          ...   \n",
       "5047   26     26    26            1           0            0            0   \n",
       "5048   27     27    27            1           0            0            0   \n",
       "5049   28     28    28            1           0            0            0   \n",
       "5050   29     29    29            1           0            0            0   \n",
       "5051   30     30    30            1           0            0            0   \n",
       "\n",
       "      label_Grey  label_Orange  label_Pink  label_Purple  label_Red  \\\n",
       "0              0             0           0             0          0   \n",
       "1              0             0           0             0          0   \n",
       "2              0             0           0             0          0   \n",
       "3              0             0           1             0          0   \n",
       "4              0             0           0             0          0   \n",
       "...          ...           ...         ...           ...        ...   \n",
       "5047           0             0           0             0          0   \n",
       "5048           0             0           0             0          0   \n",
       "5049           0             0           0             0          0   \n",
       "5050           0             0           0             0          0   \n",
       "5051           0             0           0             0          0   \n",
       "\n",
       "      label_White  label_Yellow  \n",
       "0               0             0  \n",
       "1               0             0  \n",
       "2               0             0  \n",
       "3               0             0  \n",
       "4               0             0  \n",
       "...           ...           ...  \n",
       "5047            0             0  \n",
       "5048            0             0  \n",
       "5049            0             0  \n",
       "5050            0             0  \n",
       "5051            0             0  \n",
       "\n",
       "[5052 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../datas/RGB_color_labels.csv') # read the dataset using pandas library\n",
    "dataset = pd.get_dummies(dataset, columns=['label']) # adds 11 new columns that one hot encodes the class of the color\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=8) #train_dataset = 80% of total dataset  \n",
    "#random_state = any int value means every time when you run your program you will get the same output for train and test dataset, random_state is None by default which means every time when you run your program you will get different output because of splitting between train and test varies within \n",
    "test_dataset = dataset.drop(train_dataset.index) #remove train_dataset from dataframe to get test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates the dataset(that will be the input) and the labels(that will be the class of the input values). This part is for training.\n",
    "train_labels = pd.DataFrame()\n",
    "for x in ['label_Red', 'label_Green', 'label_Blue', 'label_Yellow', 'label_Orange', 'label_Pink', 'label_Purple', 'label_Brown', 'label_Grey', 'label_Black', 'label_White']:\n",
    "    train_labels[x] = train_dataset.pop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates the dataset(that will be the input) and the labels(that will be the class of the input values). This part is for testing.\n",
    "test_labels = pd.DataFrame()\n",
    "for x in ['label_Red', 'label_Green', 'label_Blue', 'label_Yellow', 'label_Orange', 'label_Pink', 'label_Purple', 'label_Brown', 'label_Grey', 'label_Black', 'label_White']:\n",
    "    test_labels[x] = test_dataset.pop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts all data into numpy arrays\n",
    "# Why convert? Because the code gives a lot of errors if you did not input a numpy or tensors array to the neural network.\n",
    "# I will leave to the reader to research about tensors in the documentation. https://www.tensorflow.org/guide/tensor\n",
    "train_dataset = np.array(train_dataset)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels = np.argmax(train_labels, axis=1)\n",
    "\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a deep neural network model\n",
    "# 1 input layer - 3 neurons(RGB values)\n",
    "# 4 hidden layers - 15 neurons each layer\n",
    "# 1 output layer - 11 neurons(11 number of different classes ex. label_Black, label_Blue, etc)\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(3, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu', input_shape=(3,)))\n",
    "    for i in range(1,5):\n",
    "        model.add(tf.keras.layers.Dense(15, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(11))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    model.build()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in a variable\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this saves the whole model including the loss function used, everything etc.\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "global models_path\n",
    "models_path = \"../trained_models\"\n",
    "\n",
    "\n",
    "if os.listdir(f\"{models_path}\"):\n",
    "    # Makes the model folder\n",
    "    last_model_num = os.listdir(f\"{models_path}\")[-1][-1]\n",
    "    os.mkdir(f\"{models_path}/model{int(last_model_num) + 1}\")\n",
    "    \n",
    "    # Makes a readme file that contains information on when was this created\n",
    "    last_model = os.listdir(f\"{models_path}\")[-1]\n",
    "    with open(f\"{models_path}/{last_model}/readme.txt\", \"w+\") as f:\n",
    "        f.write(f\"Model created on: {str(datetime.now())}\")\n",
    "\n",
    "# If there are no models on path\n",
    "elif not os.listdir(f\"{models_path}\"):\n",
    "    # Makes the model folder\n",
    "    os.mkdir(f\"{models_path}/model1\")\n",
    "\n",
    "    # Makes a readme file that contains information on when was this created\n",
    "    with open(f\"{models_path}/model1/readme.txt\", \"w+\") as f:\n",
    "        f.write(f\"Model created on: {str(datetime.now())}\")\n",
    "\n",
    "last_model = os.listdir(f\"{models_path}\")[-1]\n",
    "os.makedirs(f\"{models_path}/{last_model}/saved_per_train/train1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 171ms/step - loss: 45.9254 - accuracy: 0.1168 - val_loss: 40.8680 - val_accuracy: 0.1059\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.8766 - accuracy: 0.1168 - val_loss: 31.5798 - val_accuracy: 0.1059\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.6602 - accuracy: 0.1163 - val_loss: 24.4178 - val_accuracy: 0.0921\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21.5108 - accuracy: 0.1059 - val_loss: 18.8906 - val_accuracy: 0.0891\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.4910 - accuracy: 0.1071 - val_loss: 14.1482 - val_accuracy: 0.1020\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.2469 - accuracy: 0.1165 - val_loss: 10.3389 - val_accuracy: 0.1059\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1303 - accuracy: 0.0789 - val_loss: 8.4571 - val_accuracy: 0.0406\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7415 - accuracy: 0.0388 - val_loss: 7.0255 - val_accuracy: 0.0406\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3549 - accuracy: 0.0317 - val_loss: 5.6702 - val_accuracy: 0.0337\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2282 - accuracy: 0.0688 - val_loss: 4.7216 - val_accuracy: 0.1535\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.3938 - accuracy: 0.1650 - val_loss: 3.9861 - val_accuracy: 0.2178\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7857 - accuracy: 0.2239 - val_loss: 3.4859 - val_accuracy: 0.2594\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.3296 - accuracy: 0.2457 - val_loss: 3.0356 - val_accuracy: 0.2564\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.9341 - accuracy: 0.2472 - val_loss: 2.6695 - val_accuracy: 0.2505\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5840 - accuracy: 0.2432 - val_loss: 2.3131 - val_accuracy: 0.2396\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.3019 - accuracy: 0.2157 - val_loss: 2.1170 - val_accuracy: 0.2822\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.1312 - accuracy: 0.3001 - val_loss: 1.9671 - val_accuracy: 0.4257\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.9894 - accuracy: 0.3906 - val_loss: 1.8688 - val_accuracy: 0.4475\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8856 - accuracy: 0.4179 - val_loss: 1.7862 - val_accuracy: 0.4743\n",
      "Epoch 20/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8178 - accuracy: 0.4560\n",
      "Epoch 20: saving model to ../trained_models/model2/saved_per_train/train1\\Epoch20_loss1.80\n",
      "INFO:tensorflow:Assets written to: ../trained_models/model2/saved_per_train/train1\\Epoch20_loss1.80\\assets\n",
      "5/5 [==============================] - 3s 691ms/step - loss: 1.7978 - accuracy: 0.4557 - val_loss: 1.7307 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7435 - accuracy: 0.4810 - val_loss: 1.6737 - val_accuracy: 0.5149\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6836 - accuracy: 0.4891 - val_loss: 1.6213 - val_accuracy: 0.5158\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6371 - accuracy: 0.4760 - val_loss: 1.5815 - val_accuracy: 0.5079\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5992 - accuracy: 0.4889 - val_loss: 1.5495 - val_accuracy: 0.5238\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5705 - accuracy: 0.5134 - val_loss: 1.5172 - val_accuracy: 0.5297\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5394 - accuracy: 0.5109 - val_loss: 1.4877 - val_accuracy: 0.5228\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5169 - accuracy: 0.4876 - val_loss: 1.4659 - val_accuracy: 0.5248\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4948 - accuracy: 0.5035 - val_loss: 1.4471 - val_accuracy: 0.5307\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4778 - accuracy: 0.5079 - val_loss: 1.4296 - val_accuracy: 0.5267\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4578 - accuracy: 0.5094 - val_loss: 1.4167 - val_accuracy: 0.5228\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4452 - accuracy: 0.4874 - val_loss: 1.4007 - val_accuracy: 0.5158\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4276 - accuracy: 0.5064 - val_loss: 1.3866 - val_accuracy: 0.5267\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4140 - accuracy: 0.5082 - val_loss: 1.3737 - val_accuracy: 0.5267\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4012 - accuracy: 0.5072 - val_loss: 1.3607 - val_accuracy: 0.5267\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3886 - accuracy: 0.5079 - val_loss: 1.3483 - val_accuracy: 0.5257\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3791 - accuracy: 0.5082 - val_loss: 1.3378 - val_accuracy: 0.5248\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3694 - accuracy: 0.5069 - val_loss: 1.3285 - val_accuracy: 0.5238\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3579 - accuracy: 0.5079 - val_loss: 1.3209 - val_accuracy: 0.5277\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3485 - accuracy: 0.5067 - val_loss: 1.3168 - val_accuracy: 0.5277\n",
      "Epoch 40/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3302 - accuracy: 0.5230\n",
      "Epoch 40: saving model to ../trained_models/model2/saved_per_train/train1\\Epoch40_loss1.34\n",
      "INFO:tensorflow:Assets written to: ../trained_models/model2/saved_per_train/train1\\Epoch40_loss1.34\\assets\n",
      "5/5 [==============================] - 4s 896ms/step - loss: 1.3422 - accuracy: 0.5079 - val_loss: 1.3074 - val_accuracy: 0.5267\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3314 - accuracy: 0.5069 - val_loss: 1.2981 - val_accuracy: 0.5337\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 1.3255 - accuracy: 0.5089 - val_loss: 1.2910 - val_accuracy: 0.5406\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3160 - accuracy: 0.5119 - val_loss: 1.2829 - val_accuracy: 0.5287\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3109 - accuracy: 0.5092 - val_loss: 1.2754 - val_accuracy: 0.5297\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.3001 - accuracy: 0.5104 - val_loss: 1.2694 - val_accuracy: 0.5287\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2946 - accuracy: 0.5005 - val_loss: 1.2624 - val_accuracy: 0.5287\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2862 - accuracy: 0.5129 - val_loss: 1.2555 - val_accuracy: 0.5356\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2789 - accuracy: 0.5116 - val_loss: 1.2446 - val_accuracy: 0.5356\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2674 - accuracy: 0.5136 - val_loss: 1.2360 - val_accuracy: 0.5446\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2633 - accuracy: 0.5000 - val_loss: 1.2287 - val_accuracy: 0.5307\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2538 - accuracy: 0.5017 - val_loss: 1.2239 - val_accuracy: 0.5376\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.2474 - accuracy: 0.5168 - val_loss: 1.2199 - val_accuracy: 0.5376\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.2397 - accuracy: 0.5178 - val_loss: 1.2029 - val_accuracy: 0.5436\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.2304 - accuracy: 0.5191 - val_loss: 1.1977 - val_accuracy: 0.5396\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.2247 - accuracy: 0.5134 - val_loss: 1.1948 - val_accuracy: 0.5366\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2188 - accuracy: 0.5171 - val_loss: 1.1859 - val_accuracy: 0.5426\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2074 - accuracy: 0.5272 - val_loss: 1.1804 - val_accuracy: 0.5515\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2021 - accuracy: 0.5225 - val_loss: 1.1725 - val_accuracy: 0.5446\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1932 - accuracy: 0.5220 - val_loss: 1.1670 - val_accuracy: 0.5366\n",
      "Epoch 60/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1822 - accuracy: 0.5090\n",
      "Epoch 60: saving model to ../trained_models/model2/saved_per_train/train1\\Epoch60_loss1.19\n",
      "INFO:tensorflow:Assets written to: ../trained_models/model2/saved_per_train/train1\\Epoch60_loss1.19\\assets\n",
      "5/5 [==============================] - 3s 716ms/step - loss: 1.1939 - accuracy: 0.4993 - val_loss: 1.1595 - val_accuracy: 0.5386\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1865 - accuracy: 0.5205 - val_loss: 1.1660 - val_accuracy: 0.5455\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1850 - accuracy: 0.5200 - val_loss: 1.1463 - val_accuracy: 0.5485\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.1676 - accuracy: 0.5312 - val_loss: 1.1443 - val_accuracy: 0.5624\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1656 - accuracy: 0.5262 - val_loss: 1.1367 - val_accuracy: 0.5535\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1559 - accuracy: 0.5265 - val_loss: 1.1262 - val_accuracy: 0.5515\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1513 - accuracy: 0.5282 - val_loss: 1.1194 - val_accuracy: 0.5505\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1437 - accuracy: 0.5267 - val_loss: 1.1187 - val_accuracy: 0.5525\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1414 - accuracy: 0.5255 - val_loss: 1.1114 - val_accuracy: 0.5554\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1338 - accuracy: 0.5260 - val_loss: 1.1033 - val_accuracy: 0.5594\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1294 - accuracy: 0.5294 - val_loss: 1.1013 - val_accuracy: 0.5485\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1253 - accuracy: 0.5272 - val_loss: 1.0959 - val_accuracy: 0.5604\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1189 - accuracy: 0.5324 - val_loss: 1.0866 - val_accuracy: 0.5604\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1126 - accuracy: 0.5260 - val_loss: 1.0838 - val_accuracy: 0.5515\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.1073 - accuracy: 0.5317 - val_loss: 1.0799 - val_accuracy: 0.5564\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1029 - accuracy: 0.5307 - val_loss: 1.0758 - val_accuracy: 0.5693\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0974 - accuracy: 0.5418 - val_loss: 1.0701 - val_accuracy: 0.5614\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0950 - accuracy: 0.5317 - val_loss: 1.0698 - val_accuracy: 0.5554\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.0875 - accuracy: 0.5312 - val_loss: 1.0612 - val_accuracy: 0.5653\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.0840 - accuracy: 0.5346 - val_loss: 1.0579 - val_accuracy: 0.5713\n",
      "Epoch 80/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1215 - accuracy: 0.5260\n",
      "Epoch 80: saving model to ../trained_models/model2/saved_per_train/train1\\Epoch80_loss1.08\n",
      "INFO:tensorflow:Assets written to: ../trained_models/model2/saved_per_train/train1\\Epoch80_loss1.08\\assets\n",
      "5/5 [==============================] - 3s 761ms/step - loss: 1.0797 - accuracy: 0.5383 - val_loss: 1.0515 - val_accuracy: 0.5624\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0760 - accuracy: 0.5341 - val_loss: 1.0533 - val_accuracy: 0.5604\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0710 - accuracy: 0.5339 - val_loss: 1.0425 - val_accuracy: 0.5584\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0648 - accuracy: 0.5379 - val_loss: 1.0378 - val_accuracy: 0.5644\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0615 - accuracy: 0.5386 - val_loss: 1.0341 - val_accuracy: 0.5644\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0554 - accuracy: 0.5416 - val_loss: 1.0321 - val_accuracy: 0.5624\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0546 - accuracy: 0.5406 - val_loss: 1.0268 - val_accuracy: 0.5604\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0495 - accuracy: 0.5517 - val_loss: 1.0229 - val_accuracy: 0.5723\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0441 - accuracy: 0.5586 - val_loss: 1.0188 - val_accuracy: 0.5653\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0409 - accuracy: 0.5547 - val_loss: 1.0113 - val_accuracy: 0.5663\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0360 - accuracy: 0.5445 - val_loss: 1.0103 - val_accuracy: 0.5733\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0317 - accuracy: 0.5547 - val_loss: 1.0063 - val_accuracy: 0.5812\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0329 - accuracy: 0.5599 - val_loss: 0.9998 - val_accuracy: 0.5653\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0261 - accuracy: 0.5529 - val_loss: 0.9969 - val_accuracy: 0.5663\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0202 - accuracy: 0.5641 - val_loss: 0.9924 - val_accuracy: 0.6010\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0151 - accuracy: 0.5831 - val_loss: 0.9879 - val_accuracy: 0.5881\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0130 - accuracy: 0.5621 - val_loss: 0.9900 - val_accuracy: 0.5921\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0131 - accuracy: 0.5586 - val_loss: 0.9789 - val_accuracy: 0.5871\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0040 - accuracy: 0.5836 - val_loss: 0.9800 - val_accuracy: 0.5990\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0026 - accuracy: 0.5861 - val_loss: 0.9766 - val_accuracy: 0.5881\n",
      "Epoch 100/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9882 - accuracy: 0.5750\n",
      "Epoch 100: saving model to ../trained_models/model2/saved_per_train/train1\\Epoch100_loss1.00\n",
      "INFO:tensorflow:Assets written to: ../trained_models/model2/saved_per_train/train1\\Epoch100_loss1.00\\assets\n",
      "5/5 [==============================] - 3s 697ms/step - loss: 0.9977 - accuracy: 0.5797 - val_loss: 0.9757 - val_accuracy: 0.6059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b41356e5e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "checkpoint_path = f\"{models_path}/{last_model}/saved_per_train/train1\" + \"/Epoch{epoch:02d}_loss{loss:.2f}\"\n",
    "csv_logger = CSVLogger(f\"{models_path}/{last_model}/saved_per_train/train1/logs.csv\", separator=',', append=False)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='accuracy',\n",
    "                                                 save_freq=100) # if save_freq='epochs' it saves the model per epoch\n",
    "                                                                # if save_freq=int_type it saves the model per <int_type> of batches\n",
    "# Train the model with the new callback\n",
    "model.fit(train_dataset, \n",
    "          train_labels,  \n",
    "          epochs=100,\n",
    "          batch_size = 1000,\n",
    "          validation_data=(test_dataset, test_labels),\n",
    "          callbacks=[cp_callback, csv_logger], # Pass callback to training\n",
    "          shuffle=True)  \n",
    "\n",
    "# This may generate warnings related to saving the state of the optimizer.\n",
    "# These warnings (and similar warnings throughout this notebook)\n",
    "# are in place to discourage outdated usage, and can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part finds the latest train in the model\n",
    "last_trained = os.listdir(f\"{models_path}/{last_model}/saved_per_train/\")[-1]\n",
    "last_trained_checkpoint_list = os.listdir(f\"{models_path}/{last_model}/saved_per_train/{last_trained}\")\n",
    "last_trained_checkpoint_list.remove('logs.csv') # deletes the csv logs file in the list because we dont need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part saves the weights in a excel file\n",
    "import xlsxwriter\n",
    "\n",
    "for model in last_trained_checkpoint_list:\n",
    "    loaded_model = tf.keras.models.load_model(f\"{models_path}/{last_model}/saved_per_train/{last_trained}/{model}\")\n",
    "\n",
    "    relative_row_idx = 0 # this is for writing bias\n",
    "    row_idx = 0\n",
    "    max_row_idx = 0\n",
    "    column_idx = 0\n",
    "\n",
    "    workbook = xlsxwriter.Workbook(f\"{models_path}/{last_model}/saved_per_train/{last_trained}/{model}/saved_weights_biases.xlsx\")\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    for layer in loaded_model.layers:\n",
    "        for row_weights in layer.get_weights()[0].T: # the reason I transposed the matrix because tensorflow makes weights in transposed position of matrix\n",
    "            for weights in row_weights:\n",
    "                worksheet.write(row_idx, column_idx, weights)\n",
    "                column_idx += 1\n",
    "\n",
    "            column_idx += 1\n",
    "            worksheet.write(row_idx, column_idx, layer.get_weights()[1].T[relative_row_idx]) # the reason I transposed the matrix because tensorflow makes weights in transposed position of matrix\n",
    "            relative_row_idx += 1\n",
    "            row_idx += 1\n",
    "            column_idx = 0\n",
    "\n",
    "        relative_row_idx = 0\n",
    "        row_idx += 2\n",
    "    workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# this part just evaluates the model how accurate it is in predicting data that it have not seen before\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m(test_dataset, test_labels, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "# this part just evaluates the model how accurate it is in predicting data that it have not seen before\n",
    "model.evaluate(test_dataset, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -5.307821  ,  -5.9415846 ,  -0.9156288 , -10.054424  ,\n",
       "        -6.2752447 ,   3.4066713 ,   3.8608985 ,  -2.1819472 ,\n",
       "         0.38721243, -13.704093  ,  -3.354857  ], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_dataset)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 1.2891 - accuracy: 0.5574 - 257ms/epoch - 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2890599966049194, 0.5574257373809814]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this loads the whole model saved\n",
    "# verbose just means what do you want to see in the outputs(what metrics do you want to see etc.)\n",
    "new_model = tf.keras.models.load_model(f\"{models_path}/{last_model}/saved_per_train/{last_trained}/{model}\")\n",
    "new_model.evaluate(test_dataset, test_labels, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('deep_learning_code')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94ae5b382a51005fca8da01575be2d2af1d447d51e335e66e884b29c6c326d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red</th>\n",
       "      <th>green</th>\n",
       "      <th>blue</th>\n",
       "      <th>label_Black</th>\n",
       "      <th>label_Blue</th>\n",
       "      <th>label_Brown</th>\n",
       "      <th>label_Green</th>\n",
       "      <th>label_Grey</th>\n",
       "      <th>label_Orange</th>\n",
       "      <th>label_Pink</th>\n",
       "      <th>label_Purple</th>\n",
       "      <th>label_Red</th>\n",
       "      <th>label_White</th>\n",
       "      <th>label_Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>139</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>83</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144</td>\n",
       "      <td>249</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168</td>\n",
       "      <td>25</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>182</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5051</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5052 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      red  green  blue  label_Black  label_Blue  label_Brown  label_Green  \\\n",
       "0      20    139   240            0           1            0            0   \n",
       "1     174     83    72            0           0            1            0   \n",
       "2     144    249   131            0           0            0            1   \n",
       "3     168     25   156            0           0            0            0   \n",
       "4      30    182   136            0           0            0            1   \n",
       "...   ...    ...   ...          ...         ...          ...          ...   \n",
       "5047   26     26    26            1           0            0            0   \n",
       "5048   27     27    27            1           0            0            0   \n",
       "5049   28     28    28            1           0            0            0   \n",
       "5050   29     29    29            1           0            0            0   \n",
       "5051   30     30    30            1           0            0            0   \n",
       "\n",
       "      label_Grey  label_Orange  label_Pink  label_Purple  label_Red  \\\n",
       "0              0             0           0             0          0   \n",
       "1              0             0           0             0          0   \n",
       "2              0             0           0             0          0   \n",
       "3              0             0           1             0          0   \n",
       "4              0             0           0             0          0   \n",
       "...          ...           ...         ...           ...        ...   \n",
       "5047           0             0           0             0          0   \n",
       "5048           0             0           0             0          0   \n",
       "5049           0             0           0             0          0   \n",
       "5050           0             0           0             0          0   \n",
       "5051           0             0           0             0          0   \n",
       "\n",
       "      label_White  label_Yellow  \n",
       "0               0             0  \n",
       "1               0             0  \n",
       "2               0             0  \n",
       "3               0             0  \n",
       "4               0             0  \n",
       "...           ...           ...  \n",
       "5047            0             0  \n",
       "5048            0             0  \n",
       "5049            0             0  \n",
       "5050            0             0  \n",
       "5051            0             0  \n",
       "\n",
       "[5052 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../datas/RGB_color_labels.csv') # read the dataset using pandas library\n",
    "dataset = pd.get_dummies(dataset, columns=['label']) # adds 11 new columns that one hot encodes the class of the color\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=8) #train_dataset = 80% of total dataset  \n",
    "#random_state = any int value means every time when you run your program you will get the same output for train and test dataset, random_state is None by default which means every time when you run your program you will get different output because of splitting between train and test varies within \n",
    "test_dataset = dataset.drop(train_dataset.index) #remove train_dataset from dataframe to get test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates the dataset(that will be the input) and the labels(that will be the class of the input values). This part is for training.\n",
    "train_labels = pd.DataFrame()\n",
    "for x in ['label_Red', 'label_Green', 'label_Blue', 'label_Yellow', 'label_Orange', 'label_Pink', 'label_Purple', 'label_Brown', 'label_Grey', 'label_Black', 'label_White']:\n",
    "    train_labels[x] = train_dataset.pop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates the dataset(that will be the input) and the labels(that will be the class of the input values). This part is for testing.\n",
    "test_labels = pd.DataFrame()\n",
    "for x in ['label_Red', 'label_Green', 'label_Blue', 'label_Yellow', 'label_Orange', 'label_Pink', 'label_Purple', 'label_Brown', 'label_Grey', 'label_Black', 'label_White']:\n",
    "    test_labels[x] = test_dataset.pop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts all data into numpy arrays\n",
    "# Why convert? Because the code gives a lot of errors if you did not input a numpy or tensors array to the neural network.\n",
    "# I will leave to the reader to research about tensors in the documentation. https://www.tensorflow.org/guide/tensor\n",
    "train_dataset = np.array(train_dataset)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels = np.argmax(train_labels, axis=1)\n",
    "\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating a deep neural network model\n",
    "# 1 input layer - 3 neurons(RGB values)\n",
    "# 4 hidden layers - 15 neurons each layer\n",
    "# 1 output layer - 11 neurons(11 number of different classes ex. label_Black, label_Blue, etc)\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(3, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu', input_shape=(3,)))\n",
    "    for i in range(1,5):\n",
    "        model.add(tf.keras.layers.Dense(15, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(11))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    model.build()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in a variable\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this saves the whole model including the loss function used, everything etc.\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "global models_path\n",
    "models_path = \"../trained_models\"\n",
    "\n",
    "\n",
    "if os.listdir(f\"{models_path}\"):\n",
    "    # Makes the model folder\n",
    "    last_model_num = os.listdir(f\"{models_path}\")[-1][-1]\n",
    "    os.mkdir(f\"{models_path}/model{int(last_model_num) + 1}\")\n",
    "    \n",
    "    # Makes a readme file that contains information on when was this created\n",
    "    last_model = os.listdir(f\"{models_path}\")[-1]\n",
    "    with open(f\"{models_path}/{last_model}/readme.txt\", \"w+\") as f:\n",
    "        f.write(f\"Model created on: {str(datetime.now())}\")\n",
    "\n",
    "# If there are no models on path\n",
    "elif not os.listdir(f\"{models_path}\"):\n",
    "    # Makes the model folder\n",
    "    os.mkdir(f\"{models_path}/model1\")\n",
    "\n",
    "    # Makes a readme file that contains information on when was this created\n",
    "    with open(f\"{models_path}/model1/readme.txt\", \"w+\") as f:\n",
    "        f.write(f\"Model created on: {str(datetime.now())}\")\n",
    "\n",
    "last_model = os.listdir(f\"{models_path}\")[-1]\n",
    "os.mkdir(f\"{models_path}/{last_model}/saved_per_train\")\n",
    "os.mkdir(f\"{models_path}/{last_model}/saved_per_train/train1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 81ms/step - loss: 29.2472 - accuracy: 0.0047 - val_loss: 23.9694 - val_accuracy: 0.0406\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20.9883 - accuracy: 0.0332 - val_loss: 16.3875 - val_accuracy: 0.0733\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.0506 - accuracy: 0.0997 - val_loss: 10.8713 - val_accuracy: 0.2168\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1122 - accuracy: 0.2197 - val_loss: 9.2551 - val_accuracy: 0.2168\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5054 - accuracy: 0.2197 - val_loss: 7.4385 - val_accuracy: 0.2168\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8759 - accuracy: 0.2197 - val_loss: 6.1700 - val_accuracy: 0.2168\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6884 - accuracy: 0.2197 - val_loss: 4.9380 - val_accuracy: 0.2168\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5922 - accuracy: 0.2197 - val_loss: 4.0282 - val_accuracy: 0.2168\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7523 - accuracy: 0.2212 - val_loss: 3.2942 - val_accuracy: 0.2396\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1778 - accuracy: 0.2810 - val_loss: 2.9371 - val_accuracy: 0.4050\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8712 - accuracy: 0.3897 - val_loss: 2.7003 - val_accuracy: 0.3891\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6528 - accuracy: 0.3748 - val_loss: 2.5162 - val_accuracy: 0.3861\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4625 - accuracy: 0.3773 - val_loss: 2.3387 - val_accuracy: 0.3931\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2974 - accuracy: 0.3845 - val_loss: 2.2136 - val_accuracy: 0.3990\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1834 - accuracy: 0.3926 - val_loss: 2.1152 - val_accuracy: 0.4089\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.0843 - accuracy: 0.4003 - val_loss: 2.0316 - val_accuracy: 0.4119\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.0043 - accuracy: 0.4023 - val_loss: 1.9732 - val_accuracy: 0.4178\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9467 - accuracy: 0.4085 - val_loss: 1.9317 - val_accuracy: 0.4228\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9103 - accuracy: 0.4146 - val_loss: 1.9133 - val_accuracy: 0.4257\n",
      "Epoch 20/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8878 - accuracy: 0.4170\n",
      "Epoch 20: saving model to ../trained_models/model1/saved_per_train/train1\\Epoch20_loss1.89\n",
      "INFO:tensorflow:Assets written to: ../trained_models/model1/saved_per_train/train1\\Epoch20_loss1.89\\assets\n",
      "5/5 [==============================] - 2s 607ms/step - loss: 1.8890 - accuracy: 0.4159 - val_loss: 1.8941 - val_accuracy: 0.4267\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8677 - accuracy: 0.4198 - val_loss: 1.8789 - val_accuracy: 0.4267\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8518 - accuracy: 0.4221 - val_loss: 1.8643 - val_accuracy: 0.4248\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8362 - accuracy: 0.4228 - val_loss: 1.8492 - val_accuracy: 0.4248\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8208 - accuracy: 0.4248 - val_loss: 1.8345 - val_accuracy: 0.4287\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8047 - accuracy: 0.4248 - val_loss: 1.8088 - val_accuracy: 0.4277\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.7867 - accuracy: 0.4248 - val_loss: 1.7897 - val_accuracy: 0.4257\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7736 - accuracy: 0.4248 - val_loss: 1.7744 - val_accuracy: 0.4277\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.7579 - accuracy: 0.4263 - val_loss: 1.7600 - val_accuracy: 0.4297\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.7426 - accuracy: 0.4283 - val_loss: 1.7527 - val_accuracy: 0.4327\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.7334 - accuracy: 0.4285 - val_loss: 1.7355 - val_accuracy: 0.4337\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.7199 - accuracy: 0.4287 - val_loss: 1.7239 - val_accuracy: 0.4317\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.7126 - accuracy: 0.4290 - val_loss: 1.7108 - val_accuracy: 0.4297\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.7005 - accuracy: 0.4275 - val_loss: 1.6998 - val_accuracy: 0.4337\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6875 - accuracy: 0.4297 - val_loss: 1.6891 - val_accuracy: 0.4356\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6749 - accuracy: 0.4302 - val_loss: 1.6798 - val_accuracy: 0.4376\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.6644 - accuracy: 0.4320 - val_loss: 1.6686 - val_accuracy: 0.4376\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6534 - accuracy: 0.4320 - val_loss: 1.6540 - val_accuracy: 0.4376\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.6411 - accuracy: 0.4322 - val_loss: 1.6427 - val_accuracy: 0.4396\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6305 - accuracy: 0.4337 - val_loss: 1.6336 - val_accuracy: 0.4396\n",
      "Epoch 40/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6687 - accuracy: 0.4220\n",
      "Epoch 40: saving model to ../trained_models/model1/saved_per_train/train1\\Epoch40_loss1.62\n",
      "INFO:tensorflow:Assets written to: ../trained_models/model1/saved_per_train/train1\\Epoch40_loss1.62\\assets\n",
      "5/5 [==============================] - 3s 672ms/step - loss: 1.6200 - accuracy: 0.4352 - val_loss: 1.6199 - val_accuracy: 0.4396\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.6082 - accuracy: 0.4354 - val_loss: 1.6077 - val_accuracy: 0.4406\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6005 - accuracy: 0.4364 - val_loss: 1.5995 - val_accuracy: 0.4406\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5934 - accuracy: 0.4364 - val_loss: 1.5916 - val_accuracy: 0.4416\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.5847 - accuracy: 0.4377 - val_loss: 1.5870 - val_accuracy: 0.4436\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5778 - accuracy: 0.4386 - val_loss: 1.5836 - val_accuracy: 0.4446\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5716 - accuracy: 0.4409 - val_loss: 1.5754 - val_accuracy: 0.4475\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5636 - accuracy: 0.4429 - val_loss: 1.5646 - val_accuracy: 0.4426\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5548 - accuracy: 0.4441 - val_loss: 1.5542 - val_accuracy: 0.4436\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5480 - accuracy: 0.4438 - val_loss: 1.5484 - val_accuracy: 0.4475\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5432 - accuracy: 0.4451 - val_loss: 1.5428 - val_accuracy: 0.4525\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5389 - accuracy: 0.4471 - val_loss: 1.5362 - val_accuracy: 0.4545\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5319 - accuracy: 0.4473 - val_loss: 1.5270 - val_accuracy: 0.4554\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.5258 - accuracy: 0.4476 - val_loss: 1.5213 - val_accuracy: 0.4535\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5205 - accuracy: 0.4463 - val_loss: 1.5154 - val_accuracy: 0.4604\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5176 - accuracy: 0.4485 - val_loss: 1.5108 - val_accuracy: 0.4584\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.5136 - accuracy: 0.4540 - val_loss: 1.5048 - val_accuracy: 0.4564\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5084 - accuracy: 0.4560 - val_loss: 1.4995 - val_accuracy: 0.4604\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.5013 - accuracy: 0.4518 - val_loss: 1.4991 - val_accuracy: 0.4614\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4991 - accuracy: 0.4527 - val_loss: 1.4961 - val_accuracy: 0.4614\n",
      "Epoch 60/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5353 - accuracy: 0.4390\n",
      "Epoch 60: saving model to ../trained_models/model1/saved_per_train/train1\\Epoch60_loss1.49\n",
      "INFO:tensorflow:Assets written to: ../trained_models/model1/saved_per_train/train1\\Epoch60_loss1.49\\assets\n",
      "5/5 [==============================] - 4s 1s/step - loss: 1.4923 - accuracy: 0.4574 - val_loss: 1.4857 - val_accuracy: 0.4614\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4857 - accuracy: 0.4560 - val_loss: 1.4803 - val_accuracy: 0.4594\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.4802 - accuracy: 0.4552 - val_loss: 1.4741 - val_accuracy: 0.4634\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4725 - accuracy: 0.4698 - val_loss: 1.4690 - val_accuracy: 0.4812\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 1.4666 - accuracy: 0.4762 - val_loss: 1.4626 - val_accuracy: 0.4772\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.4602 - accuracy: 0.4767 - val_loss: 1.4571 - val_accuracy: 0.4921\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.4545 - accuracy: 0.4980 - val_loss: 1.4522 - val_accuracy: 0.4980\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4530 - accuracy: 0.4879 - val_loss: 1.4472 - val_accuracy: 0.4802\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4397 - accuracy: 0.4881 - val_loss: 1.4520 - val_accuracy: 0.4990\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4412 - accuracy: 0.4963 - val_loss: 1.4472 - val_accuracy: 0.4891\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4321 - accuracy: 0.4802 - val_loss: 1.4293 - val_accuracy: 0.4832\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4181 - accuracy: 0.4998 - val_loss: 1.4183 - val_accuracy: 0.4921\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4120 - accuracy: 0.4985 - val_loss: 1.4135 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.4051 - accuracy: 0.5017 - val_loss: 1.4032 - val_accuracy: 0.5020\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3904 - accuracy: 0.5116 - val_loss: 1.3933 - val_accuracy: 0.5238\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3768 - accuracy: 0.5294 - val_loss: 1.3887 - val_accuracy: 0.5317\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3645 - accuracy: 0.5356 - val_loss: 1.3678 - val_accuracy: 0.5307\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.3456 - accuracy: 0.5423 - val_loss: 1.3476 - val_accuracy: 0.5337\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3280 - accuracy: 0.5443 - val_loss: 1.3296 - val_accuracy: 0.5317\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3106 - accuracy: 0.5547 - val_loss: 1.3078 - val_accuracy: 0.5723\n",
      "Epoch 80/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2636 - accuracy: 0.5870\n",
      "Epoch 80: saving model to ../trained_models/model1/saved_per_train/train1\\Epoch80_loss1.29\n",
      "INFO:tensorflow:Assets written to: ../trained_models/model1/saved_per_train/train1\\Epoch80_loss1.29\\assets\n",
      "5/5 [==============================] - 3s 672ms/step - loss: 1.2873 - accuracy: 0.5670 - val_loss: 1.2891 - val_accuracy: 0.5574\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2703 - accuracy: 0.5695 - val_loss: 1.2677 - val_accuracy: 0.5822\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2516 - accuracy: 0.5836 - val_loss: 1.2442 - val_accuracy: 0.5941\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2305 - accuracy: 0.5883 - val_loss: 1.2267 - val_accuracy: 0.5861\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2170 - accuracy: 0.5905 - val_loss: 1.2122 - val_accuracy: 0.5871\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1971 - accuracy: 0.5918 - val_loss: 1.1973 - val_accuracy: 0.5960\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 119ms/step - loss: 1.1838 - accuracy: 0.5965 - val_loss: 1.1844 - val_accuracy: 0.5950\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1715 - accuracy: 0.5982 - val_loss: 1.1670 - val_accuracy: 0.5891\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1595 - accuracy: 0.5987 - val_loss: 1.1531 - val_accuracy: 0.5911\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1475 - accuracy: 0.5995 - val_loss: 1.1387 - val_accuracy: 0.6040\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.1336 - accuracy: 0.6029 - val_loss: 1.1230 - val_accuracy: 0.6069\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1205 - accuracy: 0.6076 - val_loss: 1.1136 - val_accuracy: 0.6089\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.1103 - accuracy: 0.6106 - val_loss: 1.1027 - val_accuracy: 0.6158\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0978 - accuracy: 0.6113 - val_loss: 1.0920 - val_accuracy: 0.6119\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0880 - accuracy: 0.6096 - val_loss: 1.0880 - val_accuracy: 0.6248\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0783 - accuracy: 0.6190 - val_loss: 1.0730 - val_accuracy: 0.6257\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0656 - accuracy: 0.6291 - val_loss: 1.0640 - val_accuracy: 0.6257\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1.0559 - accuracy: 0.6269 - val_loss: 1.0559 - val_accuracy: 0.6168\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0475 - accuracy: 0.6235 - val_loss: 1.0433 - val_accuracy: 0.6277\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.0348 - accuracy: 0.6316 - val_loss: 1.0301 - val_accuracy: 0.6366\n",
      "Epoch 100/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.9787 - accuracy: 0.6540\n",
      "Epoch 100: saving model to ../trained_models/model1/saved_per_train/train1\\Epoch100_loss1.02\n",
      "INFO:tensorflow:Assets written to: ../trained_models/model1/saved_per_train/train1\\Epoch100_loss1.02\\assets\n",
      "5/5 [==============================] - 3s 699ms/step - loss: 1.0247 - accuracy: 0.6348 - val_loss: 1.0222 - val_accuracy: 0.6416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276108f4040>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "checkpoint_path = f\"{models_path}/{last_model}/saved_per_train/train1\" + \"/Epoch{epoch:02d}_loss{loss:.2f}\"\n",
    "csv_logger = CSVLogger(f\"{models_path}/{last_model}/saved_per_train/train1/logs.csv\", separator=',', append=False)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='accuracy',\n",
    "                                                 save_freq=100) # if save_freq='epochs' it saves the model per epoch\n",
    "                                                                # if save_freq=int_type it saves the model per <int_type> of batches\n",
    "# Train the model with the new callback\n",
    "model.fit(train_dataset, \n",
    "          train_labels,  \n",
    "          epochs=100,\n",
    "          batch_size = 1000,\n",
    "          validation_data=(test_dataset, test_labels),\n",
    "          callbacks=[cp_callback, csv_logger], # Pass callback to training\n",
    "          shuffle=True)  \n",
    "\n",
    "# This may generate warnings related to saving the state of the optimizer.\n",
    "# These warnings (and similar warnings throughout this notebook)\n",
    "# are in place to discourage outdated usage, and can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Epoch100_loss1.02', 'Epoch20_loss1.89', 'Epoch40_loss1.62', 'Epoch60_loss1.49', 'Epoch80_loss1.29']\n"
     ]
    }
   ],
   "source": [
    "# This part finds the latest train in the model\n",
    "last_trained = os.listdir(f\"{models_path}/{last_model}/saved_per_train/\")[-1]\n",
    "last_trained_checkpoint_list = os.listdir(f\"{models_path}/{last_model}/saved_per_train/{last_trained}\")\n",
    "last_trained_checkpoint_list.remove('logs.csv') # deletes the csv logs file in the list because we dont need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part saves the weights in a excel file\n",
    "import xlsxwriter\n",
    "\n",
    "for model in last_trained_checkpoint_list:\n",
    "    loaded_model = tf.keras.models.load_model(f\"{models_path}/{last_model}/saved_per_train/{last_trained}/{model}\")\n",
    "\n",
    "    relative_row_idx = 0 # this is for writing bias\n",
    "    row_idx = 0\n",
    "    max_row_idx = 0\n",
    "    column_idx = 0\n",
    "\n",
    "    workbook = xlsxwriter.Workbook(f\"{models_path}/{last_model}/saved_per_train/{last_trained}/{model}/saved_weights_biases.xlsx\")\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    for layer in loaded_model.layers:\n",
    "        for row_weights in layer.get_weights()[0].T: # the reason I transposed the matrix because tensorflow makes weights in transposed position of matrix\n",
    "            for weights in row_weights:\n",
    "                worksheet.write(row_idx, column_idx, weights)\n",
    "                column_idx += 1\n",
    "\n",
    "            column_idx += 1\n",
    "            worksheet.write(row_idx, column_idx, layer.get_weights()[1].T[relative_row_idx]) # the reason I transposed the matrix because tensorflow makes weights in transposed position of matrix\n",
    "            relative_row_idx += 1\n",
    "            row_idx += 1\n",
    "            column_idx = 0\n",
    "\n",
    "        relative_row_idx = 0\n",
    "        row_idx += 2\n",
    "    workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.3876 - accuracy: 0.8782 - 48ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38763684034347534, 0.8782178163528442]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this part just evaluates the model how accurate it is in predicting data that it have not seen before\n",
    "model.evaluate(test_dataset, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -5.307821  ,  -5.9415846 ,  -0.9156288 , -10.054424  ,\n",
       "        -6.2752447 ,   3.4066713 ,   3.8608985 ,  -2.1819472 ,\n",
       "         0.38721243, -13.704093  ,  -3.354857  ], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_dataset)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 1.2891 - accuracy: 0.5574 - 257ms/epoch - 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2890599966049194, 0.5574257373809814]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this loads the whole model saved\n",
    "# verbose just means what do you want to see in the outputs(what metrics do you want to see etc.)\n",
    "new_model = tf.keras.models.load_model(f\"{models_path}/{last_model}/saved_per_train/{last_trained}/{model}\")\n",
    "new_model.evaluate(test_dataset, test_labels, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('deep_learning_code')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94ae5b382a51005fca8da01575be2d2af1d447d51e335e66e884b29c6c326d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

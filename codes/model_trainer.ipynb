{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datas/RGB_color_labels.csv') # read the dataset using pandas library\n",
    "dataset = pd.get_dummies(dataset, columns=['label']) # adds 11 new columns that one hot encodes the class of the color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=8) #train_dataset = 80% of total dataset  \n",
    "#random_state = any int value means every time when you run your program you will get the same output for train and test dataset, random_state is None by default which means every time when you run your program you will get different output because of splitting between train and test varies within \n",
    "test_dataset = dataset.drop(train_dataset.index) #remove train_dataset from dataframe to get test_dataset\n",
    "\n",
    "\n",
    "# Separates the dataset(that will be the input) and the labels(that will be the class of the input values). This part is for training.\n",
    "train_labels = pd.DataFrame()\n",
    "for x in ['label_Red', 'label_Green', 'label_Blue', 'label_Yellow', 'label_Orange', 'label_Pink', 'label_Purple', 'label_Brown', 'label_Grey', 'label_Black', 'label_White']:\n",
    "    train_labels[x] = train_dataset.pop(x)\n",
    "\n",
    "\n",
    "# Separates the dataset(that will be the input) and the labels(that will be the class of the input values). This part is for testing.\n",
    "test_labels = pd.DataFrame()\n",
    "for x in ['label_Red', 'label_Green', 'label_Blue', 'label_Yellow', 'label_Orange', 'label_Pink', 'label_Purple', 'label_Brown', 'label_Grey', 'label_Black', 'label_White']:\n",
    "    test_labels[x] = test_dataset.pop(x)\n",
    "\n",
    "\n",
    "# Converts all data into numpy arrays\n",
    "# Why convert? Because the code gives a lot of errors if you did not input a numpy or tensors array to the neural network.\n",
    "# I will leave to the reader to research about tensors in the documentation. https://www.tensorflow.org/guide/tensor\n",
    "train_dataset = np.array(train_dataset)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels = np.argmax(train_labels, axis=1)\n",
    "\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = np.argmax(test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at ../trained_models//model1/tensor_model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m tensor_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodels_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloaded_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# this loads the whole model saved\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# verbose just means what do you want to see in the outputs(what metrics do you want to see etc.)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m new_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodels_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mloaded_model\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tensor_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m new_model\u001b[38;5;241m.\u001b[39mevaluate(test_dataset, test_labels, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32md:\\Electrical Engineering Files\\Electrical engineering files\\OJT 1\\EROVOUTIKA\\activities\\deep_learning\\deep_learning_code\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Electrical Engineering Files\\Electrical engineering files\\OJT 1\\EROVOUTIKA\\activities\\deep_learning\\deep_learning_code\\lib\\site-packages\\keras\\saving\\save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    231\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[0;32m    232\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[0;32m    233\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at ../trained_models//model1/tensor_model"
     ]
    }
   ],
   "source": [
    "models_path = \"../trained_models/\" # Folder path of the models\n",
    "loaded_model = \"model1\" # Pick the name of the desired model that you want to train.\n",
    "tensor_model_path = f\"{models_path}/{loaded_model}\"\n",
    "\n",
    "# this loads the whole model saved\n",
    "# verbose just means what do you want to see in the outputs(what metrics do you want to see etc.)\n",
    "new_model = tf.keras.models.load_model(f\"{models_path}/{loaded_model}/tensor_model\")\n",
    "new_model.evaluate(test_dataset, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('deep_learning_code')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94ae5b382a51005fca8da01575be2d2af1d447d51e335e66e884b29c6c326d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datas/RGB_color_labels.csv') # read the dataset using pandas library\n",
    "dataset = pd.get_dummies(dataset, columns=['label']) # adds 11 new columns that one hot encodes the class of the color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=8) #train_dataset = 80% of total dataset  \n",
    "#random_state = any int value means every time when you run your program you will get the same output for train and test dataset, random_state is None by default which means every time when you run your program you will get different output because of splitting between train and test varies within \n",
    "test_dataset = dataset.drop(train_dataset.index) #remove train_dataset from dataframe to get test_dataset\n",
    "\n",
    "\n",
    "# Separates the dataset(that will be the input) and the labels(that will be the class of the input values). This part is for training.\n",
    "train_labels = pd.DataFrame()\n",
    "for x in ['label_Red', 'label_Green', 'label_Blue', 'label_Yellow', 'label_Orange', 'label_Pink', 'label_Purple', 'label_Brown', 'label_Grey', 'label_Black', 'label_White']:\n",
    "    train_labels[x] = train_dataset.pop(x)\n",
    "\n",
    "\n",
    "# Separates the dataset(that will be the input) and the labels(that will be the class of the input values). This part is for testing.\n",
    "test_labels = pd.DataFrame()\n",
    "for x in ['label_Red', 'label_Green', 'label_Blue', 'label_Yellow', 'label_Orange', 'label_Pink', 'label_Purple', 'label_Brown', 'label_Grey', 'label_Black', 'label_White']:\n",
    "    test_labels[x] = test_dataset.pop(x)\n",
    "\n",
    "\n",
    "# Converts all data into numpy arrays\n",
    "# Why convert? Because the code gives a lot of errors if you did not input a numpy or tensors array to the neural network.\n",
    "# I will leave to the reader to research about tensors in the documentation. https://www.tensorflow.org/guide/tensor\n",
    "train_dataset = np.array(train_dataset)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels = np.argmax(train_labels, axis=1)\n",
    "\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_labels = np.array(test_labels)\n",
    "test_labels = np.argmax(test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model_path) -> None:\n",
    "        self.model_path = model_path\n",
    "        self.train_path = f\"{self.model_path}/saved_per_train\" # The train path of the model\n",
    "        self.last_trained = os.listdir(self.train_path)[-1] # This gives the latest trained\n",
    "        self.checkpoint_list = os.listdir(f\"{self.train_path}/{self.last_trained}\")\n",
    "        try:\n",
    "            self.checkpoint_list.remove(\"logs.csv\")\n",
    "        except:\n",
    "            pass\n",
    "        self.least_loss_model = min(self.checkpoint_list, key=lambda loss_val:loss_val[-4:-1])\n",
    "        self.least_loss_checkpoint_path = f\"{self.train_path}/{self.last_trained}/{self.least_loss_model}\" # The tensor model of the latest trained\n",
    "        self.loaded_model = tf.keras.models.load_model(self.least_loss_checkpoint_path) # Loads the model\n",
    "\n",
    "    def train_model(self, epochs=100, batch_size=1000, save_freq=100):\n",
    "        self.last_trained = os.listdir(self.train_path)[-1] # This gives the latest trained\n",
    "        self.checkpoint_list = os.listdir(f\"{self.train_path}/{self.last_trained}\")\n",
    "        self.checkpoint_list.remove(\"logs.csv\")\n",
    "        self.least_loss_model = min(self.checkpoint_list, key=lambda loss_val:loss_val[-4:-1])\n",
    "        self.least_loss_checkpoint_path = f\"{self.train_path}/{self.last_trained}/{self.least_loss_model}\" # The tensor model of the latest trained\n",
    "        self.loaded_model = tf.keras.models.load_model(self.least_loss_checkpoint_path) # Loads the model\n",
    "\n",
    "        self.last_model_num = os.listdir(f\"{self.train_path}\")[-1][-1]\n",
    "        os.makedirs(f\"{self.train_path}/train{int(last_model_num) + 1}\")\n",
    "        self.last_train_folder = f\"{self.train_path}/train{int(last_model_num) + 1}\"\n",
    "\n",
    "        # Training the model\n",
    "        checkpoint_path = f\"{last_train_folder}\" + \"/Epoch{epoch:02d}_loss{loss:.2f}\"\n",
    "        csv_logger = CSVLogger(f\"{last_train_folder}/logs.csv\", separator=',', append=False)\n",
    "\n",
    "        # Create a callback that saves the model's weights\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='accuracy',\n",
    "                                                 save_freq=save_freq) # if save_freq='epochs' it saves the model per epoch\n",
    "                                                                # if save_freq=int_type it saves the model per <int_type> of batches\n",
    "\n",
    "        self.loaded_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "        # Train the model with the new callback\n",
    "        self.loaded_model.fit(train_dataset, \n",
    "                train_labels,  \n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(test_dataset, test_labels),\n",
    "                callbacks=[cp_callback, csv_logger], # Pass callback to training\n",
    "                shuffle=True) \n",
    "        # This may generate warnings related to saving the state of the optimizer.\n",
    "        # These warnings (and similar warnings throughout this notebook)\n",
    "        # are in place to discourage outdated usage, and can be ignored.\n",
    "\n",
    "    def make_csv(self, specific_train=None):\n",
    "        import xlsxwriter\n",
    "\n",
    "        if not specific_train:\n",
    "            self.last_model_num = os.listdir(f\"{self.train_path}\")[-1][-1]\n",
    "            self.train_folder = f\"{self.train_path}/train{int(self.last_model_num)}\"\n",
    "            last_trained_checkpoint_list = os.listdir(self.last_train_folder)\n",
    "            try:\n",
    "                last_trained_checkpoint_list.remove('logs.csv')\n",
    "            except:\n",
    "                pass\n",
    "        elif specific_train:\n",
    "            self.train_folder = f\"{self.train_path}/{specific_train}\"\n",
    "            last_trained_checkpoint_list = os.listdir(f\"{self.train_path}/{specific_train}\")\n",
    "            try:\n",
    "                last_trained_checkpoint_list.remove('logs.csv')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "\n",
    "\n",
    "        for model in last_trained_checkpoint_list:\n",
    "            loaded_model = tf.keras.models.load_model(f\"{self.train_folder}/{model}\")\n",
    "\n",
    "            relative_row_idx = 0 # this is for writing bias\n",
    "            row_idx = 0\n",
    "            max_row_idx = 0\n",
    "            column_idx = 0\n",
    "\n",
    "            workbook = xlsxwriter.Workbook(f\"{self.train_folder}/{model}/saved_weights_biases.xlsx\")\n",
    "            worksheet = workbook.add_worksheet()\n",
    "\n",
    "            for layer in loaded_model.layers:\n",
    "                for row_weights in layer.get_weights()[0].T: # the reason I transposed the matrix because tensorflow makes weights in transposed position of matrix\n",
    "                    for weights in row_weights:\n",
    "                        worksheet.write(row_idx, column_idx, weights)\n",
    "                        column_idx += 1\n",
    "\n",
    "                    column_idx += 1\n",
    "                    worksheet.write(row_idx, column_idx, layer.get_weights()[1].T[relative_row_idx]) # the reason I transposed the matrix because tensorflow makes weights in transposed position of matrix\n",
    "                    relative_row_idx += 1\n",
    "                    row_idx += 1\n",
    "                    column_idx = 0\n",
    "\n",
    "                relative_row_idx = 0\n",
    "                row_idx += 2\n",
    "            workbook.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model1 = ModelTrainer(\"../trained_models/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model1.make_csv(specific_train=\"train2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train1\n"
     ]
    }
   ],
   "source": [
    "print(load_model1.last_trained)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('deep_learning_code')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94ae5b382a51005fca8da01575be2d2af1d447d51e335e66e884b29c6c326d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
